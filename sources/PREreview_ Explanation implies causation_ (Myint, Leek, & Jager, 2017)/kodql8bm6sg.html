<div>Second,  in most scientific papers, causal interpretations&nbsp;of correlational studies are accompanied by 'warnings' that&nbsp;additional studies are needed to clarify the causality in a certain relationship, or that&nbsp;a limitation of the study&nbsp;is its correlational character. </div><div> Third, the vignette uses more expressive language than we anecdotally recall ("We explain" more often seems to be presented along the lines of "We expect").&nbsp;This may exaggerate the problems of language.&nbsp;</div><div>In order to increase the external validity of the vignette, we suggest to create a different vignette (point one); create a condition in which corrective information ('warnings') is added versus not added (point two) and (point three) use fewer exaggerations while doing so.&nbsp;&nbsp;</div><div><div><div>Fourth, the authors do not mention how other aspects of the scholarly communication system  also contribute to&nbsp; the overreaching in the interpretation of findings. For example,  high-rejection rates at journals make editors select articles with  "hot" headlines  and researchers' degrees of freedom stretch the evidence gathering process and potentially also change the scope of the analysis. Including these aspects in the (introduction of the) study would heighten the study's relevance.</div><div>Regarding the relevance and rationale of the&nbsp;study,&nbsp;the authors&nbsp;describe in their introduction&nbsp;two 'problems'&nbsp;that may result from interpreting correlational findings as causal. They (a) list several examples of newspapers and other media outlets, which include obvious (and amusing) erroneous interpretations and (b) note&nbsp;that also within research, errors are&nbsp;made in interpreting correlational evidence as causal. The issue here is that it is unclear which of these 'problems' (scenario a or b) the authors focus on, and therefore what the study results&nbsp;implicate. </div><div>Our impression is that the authors want to focus on scenario b,&nbsp;thus, describing potential causal explanations for correlational findings in research as 'wrong', because it suggests to other researchers that the study was actually of causal nature. This is of course a challenging statement that would give rise to an interesting discussion, regarding researchers' habits of providing potential causal explanations for their findings. There are however some issues in the manuscript that lead us to think that such a claim is not supported. </div><div>First, the introduction states that "inappropriate causal language" has been found in a few fields, such as nutritional and educational fields. However, to our anecdotalknowledge, most articles appropriately describe in their methods and discussion sections&nbsp;that an inferential approach has been used, and that one must be careful not to interpret the result as causal. In many research schools it is viewed as essential to provide some theoretical framework and possible (causal) interpretation of the current results, accompanied by a statement clarifying that the current data are correlational. If the authors argue that this is not happening correctly in scientific practice, more evidence for this argument should be brought forward in the introduction. Alternatively, the authors should specify to which specific scientific fields the results apply. </div><div>Second,  the main audience for scientific articles consists of scientists or students with moderate&nbsp;knowledge on statistical methods. It seems  inefficient to ask of researchers that they&nbsp;refrain from describing any theoretical framework that might suggest a causal relationship, because individuals without sufficient statistical and methodological knowledge might read the papers. It seems reasonable that scientific papers should mostly be comprehensible for other scientists and students with some knowledge on methods and statistics. Given that students following an introductory class in statistics were&nbsp;the&nbsp;study population, the claim that researchers in general are interpreting correlational inferential data erroneously, seems unsupported.&nbsp;</div><div>This brings us to the issue of generalizability. Do you view the students as representative of researchers, the press, or the general population? The study uses a causal design by using a randomized experiment, but has a non-random sample and does not allow for inferences. One could even consider the student "sample" as being the population and deem inferences beyond this not applicable.</div><div>Nevertheless, the authors bring up an important issue in the introduction regarding erroneous interpretations of the media (named scenario&nbsp;b above). We suggest that your paper has more clear-cut implications for the extent to which readers who are potentially not well-versed  in research and statistics (given they are students), interpret research findings as causal versus correlational, than the researcher population at large. This point of&nbsp;view may better match your&nbsp;rationale in the introduction and the examples you have included. Moreover, the students you have tested may be more representative of people-who-are-not-(yet)-well-schooled-in-statistics, such as individuals working for newspapers, than of researchers.&nbsp;</div><div>Finally, regardless of which focus the authors choose, we note that the paper shows there is a problem of how strongly expressive language can affect student's interpretation of findings, but provides little framework for how to move forward. For example, it is implied throughout the paper that it is a bad thing to stretch the scope of an inferential analysis to causal (with which we agree), but does not show how we might prevent it. The manuscript seems to imply that&nbsp;researchers should not indicate the hypotheses underlying a certain correlation at all. If this is not the opinion of the authors, we recommend sharpening the writing to clarify what is and what is not permitted from your perspective and how to move forward.</div><div><i>Specific comments about experimental approaches and methods used in the study</i>:</div></div><ul><li>It is unclear where the 68.5% comes from [page 3]. Upon reproducing, we understood where it comes from but it distracted us during the reading.</li><li>During the reading it was really difficult to understand how 20,256 students resulted in approximately 11,000 included in the tables. If this is due to the exclusion of re-takers of the test, then please indicate the difference in the text.</li></ul></div><div></div>