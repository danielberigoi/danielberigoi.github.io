\documentclass[10pt]{article}

\usepackage{fullpage}
\usepackage{setspace}
\usepackage{parskip}
\usepackage{titlesec}
\usepackage{placeins}
\usepackage{xcolor}
\usepackage{breakcites}
\usepackage{lineno}





\PassOptionsToPackage{hyphens}{url}
\usepackage[colorlinks = true,
            linkcolor = blue,
            urlcolor  = blue,
            citecolor = blue,
            anchorcolor = blue]{hyperref}
\usepackage{etoolbox}
\makeatletter
\patchcmd\@combinedblfloats{\box\@outputbox}{\unvbox\@outputbox}{}{%
  \errmessage{\noexpand\@combinedblfloats could not be patched}%
}%
\makeatother


\usepackage[round]{natbib}
\let\cite\citep




\renewenvironment{abstract}
  {{\bfseries\noindent{\abstractname}\par\nobreak}\footnotesize}
  {\bigskip}

\renewenvironment{quote}
  {\begin{tabular}{|p{13cm}}}
  {\end{tabular}}

\titlespacing{\section}{0pt}{*3}{*1}
\titlespacing{\subsection}{0pt}{*2}{*0.5}
\titlespacing{\subsubsection}{0pt}{*1.5}{0pt}


\usepackage{authblk}


\usepackage{graphicx}
\usepackage[space]{grffile}
\usepackage{latexsym}
\usepackage{textcomp}
\usepackage{longtable}
\usepackage{tabulary}
\usepackage{booktabs,array,multirow}
\usepackage{amsfonts,amsmath,amssymb}
\providecommand\citet{\cite}
\providecommand\citep{\cite}
\providecommand\citealt{\cite}
% You can conditionalize code for latexml or normal latex using this.
\newif\iflatexml\latexmlfalse
\providecommand{\tightlist}{\setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}%

\AtBeginDocument{\DeclareGraphicsExtensions{.pdf,.PDF,.eps,.EPS,.png,.PNG,.tif,.TIF,.jpg,.JPG,.jpeg,.JPEG}}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}








\begin{document}

\title{Systems JC, OHSU - PREreview of ``Cortical Representations of Speech in
a Multi-talker Auditory Scene''}



\author[1]{Daniela Saderi, Ph.D.}%
\affil[1]{Oregon Health \& Science University}%


\vspace{-1em}



  \date{\today}


\begingroup
\let\center\flushleft
\let\endcenter\endflushleft
\maketitle
\endgroup





\selectlanguage{english}
\begin{abstract}
This is a preprint journal club review of\textbf{~Cortical
Representations of Speech in a Multi-talker Auditory Scene} by Krishna C
Puvvada, Jonathan Z Simon. The preprint was originally posted on bioRxiv
on April 10, 2017 (DOI:~\url{https://doi.org/10.1101/124750}). The
authors have responded to this review, and you can find the comments
on~\href{https://www.biorxiv.org/content/early/2017/04/10/124750}{bioRxiv}.
The article is now published in~\emph{The Journal of
Neuroscience~}(DOI:~\href{http://dx.doi.org/10.1523/JNEUROSCI.0938-17.2017}{10.1523/JNEUROSCI.0938-17.2017}).
~%
\end{abstract}%




\selectlanguage{english}
\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.28\columnwidth]{figures/lbhb-logo/lbhb-logo}
\caption{{\href{https://hearingbrain.org/systemsjournalclub.php}{Systems
Neuroscience JC} - Oregon Health \& Science University
{\label{248803}}%
}}
\end{center}
\end{figure}

\section*{Review}

{\label{993054}}

Dear authors,

Thank you for posting your work as a preprint on BioRxiv. We discussed
your work at our latest (preprint) systems neuroscience journal club at
the Oregon Health \& Science University. Below is a summary of our
feedback containing our main remarks, points of discussion, and
suggestions.

This work explores the encoding and decoding properties of streaming
auditory objects in primary and secondary regions of the human auditory
cortex. Listeners were tasked to selectively attend to one of three
overlapping speech streams while MEG activity was recorded. The novel
aspect of the stimulus paradigm is the presence of three concomitant
streams instead of two. Two main questions were explored: First, is the
attended stream selectively represented in primary and/or secondary
regions of the auditory cortex? Second, if that is the case, are the
other two streams represented as a combined background, or are they
represented separately as two distinct background streams?

To answer these questions two approaches were used: encoding and
decoding strategies. The first suggestion we have about the work is
purely organizational. We believe it would help the flow of the reading
if the encoding and decoding analyses were described in the same order
in the methods, the results (including figures), and the discussion
sessions.

Regarding the encoding models, we think that it would be helpful to
describe the degree of freedom of each model. We found it hard to
evaluate if the newly proposed early-late model better describes the
data when compared to the summation model because it truly captures key
neuronal properties of auditory streaming, or if this is a result of the
higher number of parameters. While cross-validation was employed during
model fitting and addresses some of these concerns, a validation using
an out-of-sample set for prediction would provide a definitive
assessment of the potential existence and extent of overfitting.

While we appreciate that showing examples of the raw data together with
the encoding and decoding model prediction contributes invaluably to
clarity and transparency of the manuscript, we believe that figures 1
and 2 do not provide enough information for that to happen.
Particularly, figure 2 would benefit from more labeling and perhaps even
a more clear way of displaying the message.

In addition, it would be nice to see what the different models look
like. What do the filter look like for the two encoding models? How do
they compare? In line with the results of this study, one would believe
that the late component of the late model should be larger, but without
seeing the models it is hard to know for sure. Showing a representation
of the model parameters would certainly add value to this work.

The following figures in the paper are definitely clearer and well
accompany the text in the result session. However, we wondered, what
does each point in the plots represent? Is it one data point per
listener? Are they multiple data points per listener depending on the
attended stimulus? It would really help if you could mention this at
least in the caption. Perhaps adding a color coding would also help the
reader better understand the results.

Finally, you mentioned that the 85-ms boundary was fit on a per-subject
manner. Would it be possible to show a plot of those values to see how
variable this boundary is in the sample data? We also wondered what it
would happen to the model if you used the median of these values.

Thanks again for posting this work as a preprint. We really enjoyed
discussing it at our JC and we hope these comments will help make the
work even better.

Thank you,

Daniela Saderi (on behalf of the Systems JC, OHSU)

\selectlanguage{english}
\FloatBarrier
\end{document}

